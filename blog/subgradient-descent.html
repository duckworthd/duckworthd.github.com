<!DOCTYPE html>
<html lang="en">
<head>
  <!-- enable responsive design -->
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <!-- stylesheets -->
  <link rel="stylesheet" type="text/css" href="/theme/css/style.css">
  <link rel="stylesheet" type="text/css" href="/theme/css/pygments.css">
  <link rel="stylesheet" type="text/css" href="/theme/lightbox/css/lightbox.css">
  <link rel="stylesheet" type="text/css" href="/theme/font-awesome-4.3.0/css/font-awesome.min.css">

  <!-- fonts -->
  <link href='http://fonts.googleapis.com/css?family=Open+Sans:800,400,300|Inconsolata' rel='stylesheet' type='text/css'>
  <link href='http://fonts.googleapis.com/css?family=Source+Sans+Pro:700,900' rel='stylesheet' type='text/css'>
  <link href='http://fonts.googleapis.com/css?family=Lora:700' rel='stylesheet' type='text/css'>
  <link href='http://fonts.googleapis.com/css?family=Playball' rel='stylesheet' type='text/css'>

  <!-- No RSS/ATOM feeds -->


    <title>Strongly Convex</title>
    <meta charset="utf-8" />
</head>
<body>
  <div class="row">
    <div id="sidebar">
      <figure id="user_logo">
        <a href=""><div class="logo">&nbsp;</div></a>
      </figure>

      <div class="user_meta">
        <h1 id="user">
          <a  href="/"
              class="sitename">
            Strongly Convex
          </a>
        </h1>
        <h2></h2>

        <ul>
          <hr></hr>
            <li><a href="/">Blog</a></li>
            <hr></hr>
            <li><a href="/about.html">About</a></li>
            <hr></hr>
        </ul>
      </div>
    </div>

    <div id="posts">
	<header>
      <h1 class="title">
			  <a  href="/blog/subgradient-descent.html"
            rel="bookmark"
			  	  title="Permalink to Subgradient Descent">
          Subgradient Descent
        </a>
      </h1>
		  <abbr class="published">Thu 11 April 2013</abbr>
	</header>
  <article>
    <p>Not far from <a href="http://stronglyconvex.com/blog/gradient-descent.html">Gradient Descent</a> is another first-order
descent algorithm (that is, an algorithm that only relies on the first
derivative) is Subgradient Descent. In implementation, they are in fact
identical. The only difference is on the assumptions placed on the objective
function we wish to minimize, <span class="math">\(f(x)\)</span>.  If you were to follow the Subgradient
Descent algorithm to walk down a mountain, it would look something like this,</p>
<div class="pseudocode">
<ol>
<li>Look around you and see which way points the most downwards. If there are multiple directions that are equally downwards, just pick one.</li>
<li>Take a step in that direction. Then repeat.</li>
</ol>
</div>
<h1><a name="implementation" href="#implementation">How does it work?</a></h1>
<p>As before, we adopt the usual problem definition,</p>
<div class="math">$$
  \min_{x} \, f(x)
$$</div>
<p>But this time, we don't assume <span class="math">\(f\)</span> is differentiable. Instead, we assume <span class="math">\(f\)</span>
is convex, implying that for all <span class="math">\(x\)</span> there exists a <span class="math">\(g_{x}\)</span> such that,</p>
<div class="math">$$
  f(y) \ge f(x) + g_{x}^T (y - x)
$$</div>
<p>If <span class="math">\(f\)</span> is differentiable at <span class="math">\(x\)</span> and is convex, then <span class="math">\(\nabla f(x)\)</span> is the only
value for <span class="math">\(g_{x}\)</span> that satisfies this property, but if <span class="math">\(f\)</span> is convex but
non-differentiable at <span class="math">\(x\)</span>, there will be other options.</p>
<p>The set of all <span class="math">\(g_x\)</span> that satisfies this property called the
<strong>subdifferential</strong> of <span class="math">\(f\)</span> at <span class="math">\(x\)</span> and is denoted <span class="math">\(\partial f(x)\)</span>. Given that we
have an algorithm for finding a point in the subdifferential, Subgradient
Descent is</p>
<figure>
  <img src="/assets/img/subgradient_descent/subgradient.png"></img>
  <figcaption>
    $f$ is differentiable at $x_1$, so there's only one possible subgradient
    (the actual gradient). At $x_2$, $f$ isn't differentiable, so $g_2$ and
    $g_3$ are both in $\partial f(x_2)$. Image taken from [EE392o slides][subgradient].
  </figcaption>
</figure>

<div class="pseudocode">
<p><strong>Input</strong>: initial iterate <span class="math">\(x^{(0)}\)</span></p>
<ol>
<li>For <span class="math">\(t = 0, 1, \ldots\)</span><ol>
<li>if converged, return <span class="math">\(x^{(t)}\)</span></li>
<li>Compute a <a href="http://www.stanford.edu/class/ee392o/subgrad.pdf">subgradient</a> of <span class="math">\(f\)</span> at <span class="math">\(x^{(t)}\)</span>, <span class="math">\(g^{(t)} \in \partial f(x^{(t)})\)</span></li>
<li><span class="math">\(x^{(t+1)} = x^{(t)} - \alpha^{(t)} g^{(t)}\)</span></li>
</ol>
</li>
</ol>
</div>
<p>The initial iterate <span class="math">\(x^{(0)}\)</span> can be selected arbitrarily, but <span class="math">\(\alpha^{(t)}\)</span>
must be selected more carefully than in Gradient Descent. A common choice is
<span class="math">\(\frac{1}{t}\)</span>.</p>
<p><a id="example"></a></p>
<h1><a name="example" href="#example">A Small Example</a></h1>
<p>Let's watch Subgradient Descent do its thing. We'll use <span class="math">\(f(x) = |x|\)</span> as our
objective function, giving us <span class="math">\(sign(x)\)</span> as a valid way to compute subgradients.
We'll use the <a href="#polyak">Polyak Step Size</a> and initialize with <span class="math">\(x^{(0)} = 0.75\)</span>.</p>
<div class="img-center">
  <img src="/assets/img/subgradient_descent/convergence.png"></img>
  <span class="caption">
    This plot shows how the objective value changes as the number of iterations
    increase. We can see that, unlike Gradient Descent, it isn't strictly
    decreasing. This is expected!
  </span>
</div>

<div class="img-center">
  <img src="/assets/img/subgradient_descent/iterates.png"></img>
  <span class="caption">
    This plot shows the actual iterates and the objective function evaluated at
    those points. More red indicates a higher iteration number.
  </span>
</div>

<h1><a name="proof" href="#proof">Why does it work?</a></h1>
<p>Now let's prove that Subgradient Descent can find <span class="math">\(x^{*} = \arg\min_x f(x)\)</span>.
We begin by making the following assumptions,</p>
<ol>
<li><span class="math">\(f\)</span> is convex and finite for all <span class="math">\(x\)</span></li>
<li>a finite solution <span class="math">\(x^{*}\)</span> exists</li>
<li><span class="math">\(f\)</span> is Lipschitz with constant <span class="math">\(G\)</span>. That is,</li>
</ol>
<div class="math">$$
  || f(x) - f(y) ||_2 \le G || x - y ||_2 \qquad \forall x,y
$$</div>
<ol>
<li>The initial distance to <span class="math">\(x^{*}\)</span> is bounded by <span class="math">\(R\)</span></li>
</ol>
<div class="math">$$
  || x^{(0)} - x^{*} || \le R
$$</div>
<p><strong>Assumptions</strong> Looking back at the convergence proof of Gradient Descent, we
see that the main difference is in assumption 3. Before, we assumed that the
<span class="math">\(\nabla f\)</span> was Lipschitz, but now we assume that <span class="math">\(f\)</span> is Lipschitz. The
reason for this is because non-smooth functions cannot have a Lipschitz
Subgradient function (Imagine 2 different subgradients for <span class="math">\(f\)</span>, <span class="math">\(g_x\)</span> and
<span class="math">\(g_y\)</span>, such that <span class="math">\(g_x \ne g_y\)</span> and <span class="math">\(x = y\)</span>. Then <span class="math">\(||x-y||_2 = 0\)</span> but <span class="math">\(||g_x -
g_y||_2 &gt; 0\)</span>).  However, this assumption does guarantee one thing: that <span class="math">\(g_x
\le G\)</span> for all <span class="math">\(x\)</span>.</p>
<p>Assumption 4 isn't really a condition at all.  It's just a notational
convenience for later.</p>
<p><strong>Proof Outline</strong> The proof for Gradient Descent relied on <span class="math">\(f(x^{(t)}) -
f(x^{*})\)</span> decreasing with each iteration, but the proof for Subgradient Descent
relies on decreasing the (upper bound on) Euclidean distance between <span class="math">\(x^{(t)}\)</span>
and the set of all possible <span class="math">\(x^{*}\)</span>.</p>
<p>We begin by upper bounding the current distance to the optimal point by the
previous distance (<span class="math">\(||x^{(t)} - x^{*}||_2\)</span>), the previous error (<span class="math">\(f(x^{(t)}) -
f(x^{*})\)</span>), and the norm of the subgradient (<span class="math">\(||g^{(t)}||_2\)</span>).  Next, we
recursively apply the previous finding across all <span class="math">\(t\)</span> to bound the sum of
errors by the <em>initial</em> distance to <span class="math">\(x^{*}\)</span> and the sum of all subgradient
norms.  Then, we lower bound the sum of all errors with a minimum over <span class="math">\(t\)</span>,
giving us an upper bound on our error at iteration <span class="math">\(t+1\)</span>. Finally, we use
Assumption 4. to make that bound go to zero.</p>
<p><strong>Step 1</strong> Upper bound <span class="math">\(||x^{(t+1)} - x^{*}||\)</span>. Let <span class="math">\(x^{*}\)</span> be any point in
<span class="math">\(\arg\min_{x} f(x)\)</span>. Then,</p>
<div class="math">$$
\begin{align*}
  ||x^{(t+1)} - x^{*}||_2^2
  = &amp; ||x^{(t)} - \alpha^{(t)} g^{(t)} - x^{*}||_2^2
    &amp;&amp; \text{# Definition of $x^{(t+1)}$} \\
  = &amp; ||x^{(t)} - x^{*}||_2^2 - 2 \alpha^{(t)} \langle g^{(t)}, x^{(t)} - x^{*} \rangle + ( \alpha^{(t)} )^2 ||g^{(t)}||_2^2
    \\
  \le &amp; ||x^{(t)} - x^{*}||_2^2 - 2 \alpha^{(t)} ( f(x^{(t)}) - f(x^{*}) ) + ( \alpha^{(t)} )^2 ||g^{(t)}||_2^2
    \\
\end{align*}
$$</div>
<p>Our last step uses <span class="math">\(f(x^{*}) \ge f(x^{(t)}) + \langle g^{(t)}, x^{*} - x^{(t)} \rangle\)</span></p>
<p><strong>Step 2</strong> Upper bound <span class="math">\(||x^{(t+1)} - x^{*}||\)</span> by <span class="math">\(||x^{(0)} - x^{*}||\)</span>.
First, we apply Step 1 recursively to bound the current distance to <span class="math">\(x^{*}\)</span></p>
<div class="math">$$
\begin{align*}
  ||x^{(t+1)} - x^{*}||_2^2
  \le &amp; ||x^{(t)} - x^{*}||_2^2 - 2 \alpha^{(t)} ( f(x^{(t)}) - f(x^{*}) ) + ( \alpha^{(t)} )^2 ||g^{(t)}||_2^2
    \\
  \le &amp; \left( ||x^{(t-1)} - x^{*}||_2^2 - 2 \alpha^{(t-1)} ( f(x^{(t-1)}) - f(x^{*}) ) + ( \alpha^{(t-1)} )^2 ||g^{(t-1)}||_2^2 \right) \\
      &amp; \quad - 2 \alpha^{(t)} ( f(x^{(t)}) - f(x^{*}) ) + ( \alpha^{(t)} )^2 ||g^{(t)}||_2^2
      &amp;&amp; \text{# Apply recursion}\\
    = &amp; ||x^{(t-1)} - x^{*}||_2^2
        - 2 \sum_{\tau=t-1}^{t} \alpha^{(\tau)} ( f(x^{(\tau)}) - f(x^{*}) )
        + \sum_{\tau=t-1}^{t} ( \alpha^{(\tau)} )^2 ||g^{(\tau)}||_2^2 \\
  \vdots \\
  \le &amp; ||x^{(0)} - x^{*}||_2^2
        - 2 \sum_{\tau=0}^{t} \alpha^{(\tau)} ( f(x^{(\tau)}) - f(x^{*}) )
        + \sum_{\tau=0}^{t} ( \alpha^{(\tau)} )^2 ||g^{(\tau)}||_2^2 \\
\end{align*}
$$</div>
<p>Then we drop <span class="math">\(||x^{(t+1)} - x^{*}||_2^2\)</span> from the left side it's lower bounded by zero,</p>
<div class="math">$$
\begin{align*}
  0
  \le &amp; ||x^{(0)} - x^{*}||_2^2
        - 2 \sum_{\tau=0}^{t} \alpha^{(\tau)} ( f(x^{(\tau)}) - f(x^{*}) )
        + \sum_{\tau=0}^{t} ( \alpha^{(\tau)} )^2 ||g^{(\tau)}||_2^2 \\
  2 \sum_{\tau=0}^{t} \alpha^{(\tau)} ( f(x^{(\tau)}) - f(x^{*}) )
  \le &amp; ||x^{(0)} - x^{*}||_2^2
        + \sum_{\tau=0}^{t} ( \alpha^{(\tau)} )^2 ||g^{(\tau)}||_2^2 \\
\end{align*}
$$</div>
<p><strong>Step 3</strong> Upper bound current error. First, notice that we can lower bound the
contents of the sum on the left with the minimum across <span class="math">\(\tau\)</span>,</p>
<div class="math">$$
\begin{align*}
  \sum_{\tau=0}^{t} \alpha^{(\tau)} ( f(x^{(\tau)}) - f(x^{*}) )
  \ge &amp; \left( \min_{\tau \in 0 \ldots t} f(x^{(\tau)}) - f(x^{*}) \right) \sum_{\tau=0}^{t} ( \alpha^{(\tau)} )
\end{align*}
$$</div>
<p>Then divide by <span class="math">\(2 \sum_{\tau=0}^{t} ( \alpha^{(\tau)} )\)</span>,</p>
<div class="math">$$
\begin{align*}
  2 \left( \min_{\tau \in 0 \ldots t} f(x^{(\tau)}) - f(x^{*}) \right) \sum_{\tau=0}^{t} ( \alpha^{(\tau)} )
  \le &amp; 2 \sum_{\tau=0}^{t} \alpha^{(\tau)} ( f(x^{(\tau)}) - f(x^{*}) ) \\
  \le &amp; ||x^{(0)} - x^{*}||_2^2
          + \sum_{\tau=0}^{t} ( \alpha^{(\tau)} )^2 ||g^{(\tau)}||_2^2 \\
  \left( \min_{\tau \in 0 \ldots t} f(x^{(\tau)}) \right) - f(x^{*})
  \le &amp; \frac{
          ||x^{(0)} - x^{*}||_2^2
          + \sum_{\tau=0}^{t} ( \alpha^{(\tau)} )^2 ||g^{(\tau)}||_2^2
        }{
          2 \sum_{\tau=0}^{t} ( \alpha^{(\tau)} )
        } \\
  \left( \min_{\tau \in 0 \ldots t} f(x^{(\tau)}) \right) - f(x^{*})
  \le &amp; \frac{
          R^2
          + G^2 \sum_{\tau=0}^{t} ( \alpha^{(\tau)} )^2
        }{
          2 \sum_{\tau=0}^{t} ( \alpha^{(\tau)} )
        } \\
\end{align*}
$$</div>
<p><strong>Step 4</strong> Making the bound go to zero.  Let <span class="math">\(\alpha^{(\tau)} = \frac{R}{G
\sqrt{t}}\)</span> (this is the minimizer of the right hand side for constant
<span class="math">\(\alpha^{(\tau)}\)</span>). Then,</p>
<div class="math">$$
\begin{align*}
  \left( \min_{\tau \in 0 \ldots t} f(x^{(\tau)}) \right) - f(x^{*})
  \le &amp; \frac{
          R^2 + G^2 \sum_{\tau=0}^{t} ( \alpha^{(\tau)} )^2
        }{
          2 \sum_{\tau=0}^{t} ( \alpha^{(\tau)} )
        } \\
    = &amp; \frac{
          R^2 + G^2 \frac{R^2}{G^2} \sum_{\tau=0}^{t} \frac{1}{t+1}
        }{
          2 \frac{R}{G} \sum_{\tau=0}^{t} \frac{1}{\sqrt{t+1}}
        } \\
    = &amp; \frac{ RG }{ 2 \sqrt{t+1} }
        + \frac{ RG } { 2 \sqrt{t+1} }
    = \frac{ RG }{ \sqrt{t+1} }
\end{align*}
$$</div>
<p>Thus, we can conclude that if we want <span class="math">\(f(x^{(t)}) - f(x^{*}) \le \epsilon\)</span>,
we need <span class="math">\(O(\frac{1}{\epsilon^2})\)</span> iterations. Compared to Gradient
Descent's <span class="math">\(O(\frac{1}{\epsilon})\)</span> convergence rate, Subgradient Descent looks
pretty bad!</p>
<h1><a name="usage" href="#usage">When should I use it?</a></h1>
<p>As the implementation of Gradient Descent and Subgradient Descent are
essentially the same, ease of use is always the first reason to use Subgradient
Descent. Similarly, Subgradient Descent requires a minimal memory footprint,
and has thus found a large following in the large scale machine learning
community.</p>
<p>As far as black box, first-order for non-differentiable convex problems go,
it can be shown that Subgradient Descent is as (asymptotically) fast as we can
hope for. That doesn't mean Subgradient Descent is as fast as you can get for
your specific problem. Proximal Gradient methods, for example, are one such
family of algorithms that allow you to exploit the properties of differentiable
problems even if your problem isn't.</p>
<h1><a name="extensions" href="#extensions">Extensions</a></h1>
<p><strong>Step Size</strong> As stated previously, a common choice of step size is
<span class="math">\(\alpha^{(t)} = \frac{1}{t}\)</span>, but that's far from your only choice. Indeed, any
step rule that satisfies the following conditions works when inserted into the
above proof,</p>
<div class="math">$$
  \sum_{t=0}^{\infty} \alpha^{(t)} = \infty \qquad
  \sum_{t=0}^{\infty} ( \alpha^{(t)} )^2 &lt; \infty
$$</div>
<p>For example, <span class="math">\(\alpha^{(t)} = \frac{a}{b + t^{c}}\)</span> for positive constants <span class="math">\(a\)</span>
and <span class="math">\(b\)</span> and <span class="math">\(c \in (0.5, 1]\)</span> also works. These conditions are referred to as
being square-summable but not summable.</p>
<p>If <span class="math">\(f(x^{*})\)</span> is known ahead of time, another choice is <a href="http://www.stanford.edu/class/ee364b/lectures/subgrad_method_slides.pdf">Polyak's Step
Size</a>,</p>
<div class="math">$$
\alpha^{(t)} = \frac{ f(x^{(t)}) - f(x^{*}) }
                    { ||g^{(t)}||_2^2 }
$$</div>
<p>If <span class="math">\(f(x^{*})\)</span> isn't know, then <span class="math">\(\alpha^{(t)} = \frac{ f(x^{(t)}) -
f^{(t)}_{best} + \gamma^{(t)} }{ ||g^{(t)}||_2^2 }\)</span> is also valid for
<span class="math">\(f^{(t)}_{best} = \min_{\tau \in 0\ldots t} f(x^{(t)})\)</span> and <span class="math">\(\gamma^{(t)}\)</span>
being square-summable and not summable.</p>
<p><strong>Checking Convergence</strong> In short, there are no easy ways to know when to stop
with Subgradient Descent. Checking if <span class="math">\(\nabla f(x)\)</span> is small doesn't make sense
because <span class="math">\(\nabla f(x)\)</span> isn't defined at some points and <span class="math">\(g_x\)</span> doesn't
necessarily get small near <span class="math">\(x \triangleq x^{*}\)</span>. Instead, a fixed number of
iterations is typically used.</p>
<h1><a name="references" href="#references">References</a></h1>
<p><strong>Proof of Convergence</strong> The proof of convergence for Subgradient Descent is
taken nearly verbatim from Stephen Boyd's <a href="http://www.stanford.edu/class/ee392o/subgrad_method.pdf">lecture notes for
EE392o</a> course in 2003.</p>
<p><strong>Polyak Step Size</strong> The algorithm for the Polyak step size was taken from
page 23 of Stephen Boyd's <a href="http://www.stanford.edu/class/ee364b/lectures/subgrad_method_slides.pdf">lecture slides for EE364b</a>.</p>
<h1><a name="reference-impl" href="#reference-impl">Reference Implementation</a></h1>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">subgradient_descent</span><span class="p">(</span><span class="n">function</span><span class="p">,</span> <span class="n">subgradient</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">n_iterations</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Subgradient Descent</span>

<span class="sd">  Parameters</span>
<span class="sd">  ----------</span>
<span class="sd">  function : function</span>
<span class="sd">      Computes the objective function</span>
<span class="sd">  subgradient : function</span>
<span class="sd">      Computes a gradient for the objective function at x</span>
<span class="sd">  x0 : array</span>
<span class="sd">      initial value for x</span>
<span class="sd">  alpha : function</span>
<span class="sd">      function computing step sizes</span>
<span class="sd">  n_iterations : int, optional</span>
<span class="sd">      number of iterations to perform</span>

<span class="sd">  Returns</span>
<span class="sd">  -------</span>
<span class="sd">  xs : list</span>
<span class="sd">      intermediate values for x</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">xs</span> <span class="o">=</span> <span class="p">[</span><span class="n">x0</span><span class="p">]</span>
  <span class="n">x_best</span> <span class="o">=</span> <span class="n">x0</span>
  <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_iterations</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">xs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">subgradient</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x_plus</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">function</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">function</span><span class="p">(</span><span class="n">x_best</span><span class="p">),</span> <span class="n">g</span><span class="p">)</span> <span class="o">*</span> <span class="n">g</span>
    <span class="n">xs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x_plus</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">function</span><span class="p">(</span><span class="n">x_plus</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">function</span><span class="p">(</span><span class="n">x_best</span><span class="p">):</span>
      <span class="n">x_best</span> <span class="o">=</span> <span class="n">x_plus</span>
  <span class="k">return</span> <span class="n">xs</span>


<span class="k">def</span> <span class="nf">polyak</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">f_x</span><span class="p">,</span> <span class="n">f_x_best</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
  <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">g</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">f_x</span> <span class="o">-</span> <span class="n">f_x_best</span> <span class="o">+</span> <span class="mf">1.0</span><span class="o">/</span><span class="p">(</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">g</span> <span class="o">*</span> <span class="n">g</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="mf">0.0</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
  <span class="kn">import</span> <span class="nn">os</span>

  <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
  <span class="kn">import</span> <span class="nn">pylab</span> <span class="k">as</span> <span class="nn">pl</span>
  <span class="kn">import</span> <span class="nn">yannopt.plotting</span> <span class="k">as</span> <span class="nn">plotting</span>

  <span class="c1">### SUBGRADIENT DESCENT ###</span>

  <span class="n">function</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span>
  <span class="n">subgradient</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span>
  <span class="n">x0</span> <span class="o">=</span> <span class="mf">0.75</span>
  <span class="n">n_iterations</span> <span class="o">=</span> <span class="mi">10</span>

  <span class="n">iterates</span> <span class="o">=</span> <span class="n">subgradient_descent</span><span class="p">(</span><span class="n">function</span><span class="p">,</span> <span class="n">subgradient</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">polyak</span><span class="p">,</span> <span class="n">n_iterations</span><span class="o">=</span><span class="n">n_iterations</span><span class="p">)</span>
  <span class="n">iterates</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">iterates</span><span class="p">)</span>

  <span class="c1">### PLOTTING ###</span>

  <span class="n">plotting</span><span class="o">.</span><span class="n">plot_iterates_vs_function</span><span class="p">(</span><span class="n">iterates</span><span class="p">,</span> <span class="n">function</span><span class="p">,</span>
                                     <span class="n">path</span><span class="o">=</span><span class="s1">&#39;figures/iterates.png&#39;</span><span class="p">,</span> <span class="n">y_star</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
  <span class="n">plotting</span><span class="o">.</span><span class="n">plot_iteration_vs_function</span><span class="p">(</span><span class="n">iterates</span><span class="p">,</span> <span class="n">function</span><span class="p">,</span>
                                      <span class="n">path</span><span class="o">=</span><span class="s1">&#39;figures/convergence.png&#39;</span><span class="p">,</span> <span class="n">y_star</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
</code></pre></div>

<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>

    <div id="article_meta">
        Category:
          <a href="/category/optimization.html">optimization</a>
        <br />Tags:
          <a href="/tag/optimization.html">optimization</a>
,           <a href="/tag/first-order.html">first-order</a>
,           <a href="/tag/subgradient.html">subgradient</a>
    </div>
  </article>

  <footer>
    <a href="/" class="button_accent">&larr;&nbsp;&nbsp;&nbsp;Back to blog</a>
  </footer>


    </div>
  </div>


  <!-- scripts -->
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script
    type= "text/javascript"
    src="/theme/mathjax/MathJaxLocal.js"
    >
  </script>
  <script
      type="text/javascript"
      src="/theme/lightbox/js/jquery-1.11.0.min.js"
      >
  </script>
  <script
      type="text/javascript"
      src="/theme/lightbox/js/lightbox.min.js"
      >
  </script>
</body>
</html>