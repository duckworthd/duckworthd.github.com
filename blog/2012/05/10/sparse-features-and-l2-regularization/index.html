
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Sparse Features and L2 Regularization - Bayesian World</title>
  <meta name="author" content="duckworthd">

  
  <meta name="description" content="Suppose you&#8217;re doing some typical supervised learning on a gigantic dataset where the total loss over all samples for parameter $$w$$ is &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://duckworthd.github.com/blog/2012/05/10/sparse-features-and-l2-regularization">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/stylesheets/data-table.css" media="screen, projection" rel="stylesheet" type="text/css" />
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="Bayesian World" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Bayesian World</a></h1>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:duckworthd.github.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/about.html">About</a></li>
  <li><a href="http://twitter.com/#!/duck">Twitter</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">Sparse Features and L2 Regularization</h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-05-10T17:21:00-07:00" pubdate data-updated="true">May 10<span>th</span>, 2012</time>
        
      </p>
    
  </header>


<div class="entry-content"><p>  Suppose you&#8217;re doing some typical supervised learning on a gigantic dataset where the total loss over all samples for parameter $$w$$ is simply the sum of the losses of each sample $$i$$, i.e.,</p>

<p>$$
  L(w) = \sum_{i} l(x_i, y_i, w)
$$</p>

<p>  Basically any loss function you can think of in the i.i.d sample regime can be composed this way.  Since we assumed that your dataset was huge, there&#8217;s no way you&#8217;re going to be able to load it all into memory for BFGS, so you choose to use <a href="http://en.wikipedia.org/wiki/Stochastic_gradient_descent">Stochastic Gradient Descent</a>.  The update for sample $$i$$ with step size $$\eta_t$$ would then be,</p>

<p>$$
  w_{t+1} = w_t - \eta_t \nabla_w l(x_i, y_i, w_t)
$$</p>

<p>  So far, so good.  If $$\nabla_w l(x_i, y_i, w)$$ is sparse, then you only need to change a handful of $$w$$&#8217;s components.  Of course, being the astute Machine Learning expert that you are, you know that you&#8217;re going to need some regularization.  Let&#8217;s redefine the total loss and take a look at our new update equation,</p>

<p>$$
\begin{align}
  L(w) &amp; = \sum<em>{i} l(x_i, y_i, w) + \frac{\lambda}{2}||w||</em>2<sup>2</sup>  \
  w_{t+1} &amp; = w_t - \eta_t \left( \nabla_w l(x_i, y_i, w_t) + \lambda w_t \right)
\end{align}
$$</p>

<p>  Uh oh.  Now that $$w$$ appears in our Stochastic Gradient Descent update equation, you&#8217;re going to have change <em>every</em> non-zero element of $$w$$ at <em>every</em> iteration, even if $$\nabla_w l(x_i, y_i, w)$$ is sparse!  Whatever shall you do?</p>

<p>  The answer isn&#8217;t as scary as you might think.  Let&#8217;s do some algebraic manipulation from $$t=0$$,</p>

<p>$$
\begin{align}
  w_{1}
  &amp; = w_0 - \eta_0 \left( \nabla_w l(x_i, y_i, w_0) + \lambda w_0 \right) \
  &amp; = w_0 - \eta_0 \nabla_w l(x_i, y_i, w_0) - \eta_0 \lambda w_0 \
  &amp; = (1 - \eta_0 \lambda ) w_0 - \eta_0 \nabla_w l(x_i, y_i, w_0) \
  &amp; = (1 - \eta_0 \lambda ) \left(</p>

<pre><code>  w_0 - \frac{\eta_0}{1-\eta_0 \lambda } \nabla_w l(x_i, y_i, w_0)
\right) \\
</code></pre>

<p>\end{align}
$$</p>

<p>  Do you see it now?  $$L_2$$ regularization is really just a <em>rescaling</em> of $$w_t$$ at <em>every</em> iteration.  Thus instead of keeping $$w_t$$, let&#8217;s keep track of,</p>

<p>$$
\begin{align}
  c_t &amp; = \prod<em>{\tau=0}^t (1-\eta</em>{\tau} \lambda )  \
  \bar{w}_t &amp; = \frac{w_t}{c_t}
\end{align}
$$</p>

<p>  where you update $$\bar{w}_t$$ and $$c_t$$ by,</p>

<p>$$
\begin{align}
  \bar{w}<em>{t+1}
  &amp; = \bar{w}</em>t - \frac{\eta_t}{(1 - \eta_t) c_t} \nabla_w l(x_i, w_i, c_t \bar{w}<em>t) \
  c</em>{t+1}
  &amp; = (1 - \eta_t \lambda) c_t
\end{align}
$$</p>

<p>  And that&#8217;s it!  As a final note, depending what value you choose for $$\lambda$$, $$c_t$$ is going to get really big or really small pretty fast.  The usual &#8220;take the log&#8221; tricks aren&#8217;t going to fly, either, as $$c_t$$ need not be positive.  The only way around it I&#8217;ve found is to check every iteration if $$c_t$$ is getting out of hand, then transform $$\bar{w}_{t} \leftarrow \bar{w}_t c_t$$ and $$c_t \leftarrow 1$$ if it is.</p>

<p>  Finally, credit should be given where credit is due.  This is a slightly more detailed explanation of <a href="http://blog.smola.org/post/940672544/fast-quadratic-regularization-for-online-learnin">Alex Smola&#8217;s Blog Post</a> from about a year ago, which in turn is accredited to Leon Bottou.</p>
</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">duckworthd</span></span>

      








  


<time datetime="2012-05-10T17:21:00-07:00" pubdate data-updated="true">May 10<span>th</span>, 2012</time>
      


    </p>
    
      <div class="sharing">
  
  <a href="http://twitter.com/share" class="twitter-share-button" data-url="http://duckworthd.github.com/blog/2012/05/10/sparse-features-and-l2-regularization/" data-via="duck" data-counturl="http://duckworthd.github.com/blog/2012/05/10/sparse-features-and-l2-regularization/" >Tweet</a>
  
  
  
</div>

    
    <p class="meta">
      
      
        <a class="basic-alignment right" href="/blog/2012/05/10/the-limits-of-bayesian-networks/" title="Next Post: The Limits of Bayesian Networks">The Limits of Bayesian Networks &raquo;</a>
      
    </p>
  </footer>
</article>

</div>

<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2012/12/31/topic-models-via-starcraft/">Topic Models via Starcraft</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/05/10/the-limits-of-bayesian-networks/">The Limits of Bayesian Networks</a>
      </li>
    
      <li class="post">
        <a href="/blog/2012/05/10/sparse-features-and-l2-regularization/">Sparse Features and L2 Regularization</a>
      </li>
    
  </ul>
</section>


<section>
  <h1>Latest Tweets</h1>
  <ul id="tweets">
    <li class="loading">Status updating...</li>
  </ul>
  <script type="text/javascript">
    $.domReady(function(){
      getTwitterFeed("duck", 4, false);
    });
  </script>
  <script src="/javascripts/twitter.js" type="text/javascript"> </script>
  
    <a href="http://twitter.com/duck" class="twitter-follow-button" data-show-count="false">Follow @duck</a>
  
</section>





  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2012 - duckworthd -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>






  <!-- mathjax config similar to math.stackexchange -->
  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$', '$'] ],
      displayMath: [ ['$$', '$$']],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    messageStyle: "none",
    "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
  });
  </script>
  <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>
</body>
</html>
