<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Bayesian World]]></title>
  <link href="http://duckworthd.github.com/atom.xml" rel="self"/>
  <link href="http://duckworthd.github.com/"/>
  <updated>2012-05-10T20:55:59-07:00</updated>
  <id>http://duckworthd.github.com/</id>
  <author>
    <name><![CDATA[duckworthd]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[The Limits of Bayesian Networks]]></title>
    <link href="http://duckworthd.github.com/blog/2012/05/10/the-limits-of-bayesian-networks/"/>
    <updated>2012-05-10T20:03:00-07:00</updated>
    <id>http://duckworthd.github.com/blog/2012/05/10/the-limits-of-bayesian-networks</id>
    <content type="html"><![CDATA[<p>So you’re a smart guy or gal.  You have Bayesian Networks down.  <a href="http://en.wikipedia.org/wiki/Belief_propagation">Belief Propagation</a>?  “Please, I build Junction Trees in my sleep”.  What’s that, a <a href="http://www.cs.ubc.ca/~murphyk/Papers/dbnchapter.pdf">Dynamic Bayesian Network</a>?  “I’ll have a <a href="http://en.wikipedia.org/wiki/Variational_Bayesian_methods">Variational Inference</a> algorithm done by the end of the week, and if that isn’t enough I’ll whip out my <a href="http://www.cs.ubc.ca/~arnaud/doucet_johansen_tutorialPF.pdf">Particle Filter</a>.  MCMC, EM, whatever, I got this.  Give me a Bayesian Network, and I’ll show you how to do inference”, you say.</p>

<p>But believe it or not, Bayesian Networks just aren’t enough, and even if you <em>do</em> have inference in Bayesian Networks down cold, the world is far, far bigger than that.  Let’s take a look at an example.</p>

<p>A storm is coming, and it’s about to hit town A.  Unfortunately, they’re completely in the dark about it and have absolutely no idea.  Still, they’re prepared as much as they always are (<script type="math/tex">P_A</script>), and when it finally comes, they sustain damage <script type="math/tex">D_A</script> based on how much they prepared and how strong the storm was (<script type="math/tex">S</script>).  The storm then turns to town <script type="math/tex">B</script>, butseeing what happened to town A, they’re more prepared (thus the edge <script type="math/tex">D_A \rightarrow P_B</script>).  The storm finally comes, and they take damage <script type="math/tex">D_B</script>.We can make a Bayesian Network for this generative model below.</p>

<p><img class="center" src="http://duckworthd.github.com/images/bayesian-networks-arent-enough/weather-prep-1.png" /></p>

<p>So far so good, but what if we didn’t know which town <script type="math/tex">S</script> is going to hit first (<script type="math/tex">F</script>)?  Sure, we may think, “Well, if A was hit first, it’s the same as before, but if B is hit first, we have <script type="math/tex">D_B</script> pointing to <script type="math/tex">P_A</script>,” but look at what happens,</p>

<p><img class="center" src="http://duckworthd.github.com/images/bayesian-networks-arent-enough/weather-prep-2.png" /></p>

<p>Woah woah woah, a <em>loop</em>?  You just <em>know</em> that’s not allowed. We’re able to provide a “generative story”, so why can’t we make a Bayesian Network for it?  The issue here is one of <strong>identity uncertainty</strong> and <strong>context-specific independence</strong>.  If we knew the identity of the city to be hit first, we know that one of the edges in the center don’t matter.  Really, we can think of <script type="math/tex">F</script> as selecting one of two possible Bayesian Networks which differ only by one edge.  </p>

<p>At the same time, this is also a case of context-specific independence.  Given the “context” <script type="math/tex">F=A</script>, we know that <script type="math/tex">P_A</script> is independent of <script type="math/tex">D_B</script>.  On the other hand, if <script type="math/tex">F=B</script>, then <script type="math/tex">P_B</script> is independent of <script type="math/tex">D_A</script>.  Identity uncertainty and context-specific independence are really two sides to the same coin.</p>

<p>So how can we do inference?  Monte Carlo algorithms luckily seem to “just work” (see Brian Milch’s Thesis), but we don’t know a whole lot about exact or Variational Methods.  </p>

<p>There have been a number of projects over the last decade to make a “language” broader than Bayesian Networks to define generative models, including <a href="http://projects.csail.mit.edu/church/wiki/Church">MIT-Church</a>,  <a href="http://alchemy.cs.washington.edu/">Markov Logic Networks</a>, <a href="http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.29.1299">IBAL</a>, and <a href="http://people.csail.mit.edu/milch/blog/index.html">BLOG</a>.  With any luck, we’ll be teaching students how to use one of these in our undergraduate AI classes in a few years.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Sparse Features and L2 Regularization]]></title>
    <link href="http://duckworthd.github.com/blog/2012/05/10/sparse-features-and-l2-regularization/"/>
    <updated>2012-05-10T17:21:00-07:00</updated>
    <id>http://duckworthd.github.com/blog/2012/05/10/sparse-features-and-l2-regularization</id>
    <content type="html"><![CDATA[<p>Suppose you’re doing some typical supervised learning on a gigantic dataset where the total loss over all samples for parameter <script type="math/tex">w</script> is simply the sum of the losses of each sample <script type="math/tex">i</script>, i.e.,</p>

<script type="math/tex; mode=display">
  L(w) = \sum_{i} l(x_i, y_i, w)
</script>

<p>Basically any loss function you can think of in the i.i.d sample regime can be composed this way.  Since we assumed that your dataset was huge, there’s no way you’re going to be able to load it all into memory for BFGS, so you choose to use <a href="http://en.wikipedia.org/wiki/Stochastic_gradient_descent">Stochastic Gradient Descent</a>.  The update for sample <script type="math/tex">i</script> with step size <script type="math/tex">\eta_t</script> would then be,</p>

<script type="math/tex; mode=display">
  w_{t+1} = w_t - \eta_t \nabla_w l(x_i, y_i, w_t)
</script>

<p>So far, so good.  If <script type="math/tex">\nabla_w l(x_i, y_i, w)</script> is sparse, then you only need to change a handful of <script type="math/tex">w</script>’s components.  Of course, being the astute Machine Learning expert that you are, you know that you’re going to need some regularization.  Let’s redefine the total loss and take a look at our new update equation,</p>

<script type="math/tex; mode=display">
\begin{align}
  L(w) & = \sum_{i} l(x_i, y_i, w) + \frac{\lambda}{2}||w||_2^2  \\
  w_{t+1} & = w_t - \eta_t \left( \nabla_w l(x_i, y_i, w_t) + \lambda w_t \right)
\end{align}
</script>

<p>Uh oh.  Now that <script type="math/tex">w</script> appears in our Stochastic Gradient Descent update equation, you’re going to have change <em>every</em> non-zero element of <script type="math/tex">w</script> at <em>every</em> iteration, even if <script type="math/tex">\nabla_w l(x_i, y_i, w)</script> is sparse!  Whatever shall you do?</p>

<p>The answer isn’t as scary as you might think.  Let’s do some algebraic manipulation from <script type="math/tex">t=0</script>,</p>

<script type="math/tex; mode=display">
\begin{align}
  w_{1} 
  & = w_0 - \eta_0 \left( \nabla_w l(x_i, y_i, w_0) + \lambda w_0 \right) \\
  & = w_0 - \eta_0 \nabla_w l(x_i, y_i, w_0) - \eta_0 \lambda w_0 \\
  & = (1 - \eta_0 \lambda ) w_0 - \eta_0 \nabla_w l(x_i, y_i, w_0) \\
  & = (1 - \eta_0 \lambda ) \left(
      w_0 - \frac{\eta_0}{1-\eta_0 \lambda } \nabla_w l(x_i, y_i, w_0)
    \right) \\
\end{align}
</script>

<p>Do you see it now?  <script type="math/tex">L_2</script> regularization is really just a <em>rescaling</em> of <script type="math/tex">w_t</script> at <em>every</em> iteration.  Thus instead of keeping <script type="math/tex">w_t</script>, let’s keep track of,</p>

<script type="math/tex; mode=display">
\begin{align}
  c_t & = \prod_{\tau=0}^t (1-\eta_{\tau} \lambda )  \\
  \bar{w}_t & = \frac{w_t}{c_t}
\end{align}
</script>

<p>where you update <script type="math/tex">\bar{w}_t</script> and <script type="math/tex">c_t</script> by,</p>

<script type="math/tex; mode=display">
\begin{align}
  \bar{w}_{t+1} 
  & = \bar{w}_t - \frac{\eta_t}{(1 - \eta_t) c_t} \nabla_w l(x_i, w_i, c_t \bar{w}_t) \\
  c_{t+1} 
  & = (1 - \eta_t \lambda) c_t
\end{align}
</script>

<p>And that’s it!  As a final note, depending what value you choose for <script type="math/tex">\lambda</script>, <script type="math/tex">c_t</script> is going to get really big or really small pretty fast.  The usual “take the log” tricks aren’t going to fly, either, as <script type="math/tex">c_t</script> need not be positive.  The only way around it I’ve found is to check every iteration if <script type="math/tex">c_t</script> is getting out of hand, then transform <script type="math/tex">\bar{w}_{t} \leftarrow \bar{w}_t c_t</script> and <script type="math/tex">c_t \leftarrow 1</script> if it is.</p>

<p>Finally, credit should be given where credit is due.  This is a slightly more detailed explanation of <a href="http://blog.smola.org/post/940672544/fast-quadratic-regularization-for-online-learnin">Alex Smola’s Blog Post</a> from about a year ago, which in turn is accredited to Leon Bottou.</p>
]]></content>
  </entry>
  
</feed>
